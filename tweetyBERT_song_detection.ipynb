{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "import shutil\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn import cluster\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "\n",
    "data_root = \"/home/george-vengrovski/Documents/TweetyBERT/llb3_data_matrices\"\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psuedo_label_generation\n",
    "\n",
    "data_root = \"/home/george-vengrovski/Documents/canary_song_detector/data\"\n",
    "train = \"/home/george-vengrovski/Documents/canary_song_detector/train\"\n",
    "test = \"/home/george-vengrovski/Documents/canary_song_detector/test\"\n",
    "\n",
    "processor = psuedo_label_generation.SpectrogramProcessor(data_root=data_root, train_dir=train, test_dir=test, n_clusters=100)\n",
    "\n",
    "### CAREFUL\n",
    "processor.clear_directory(train)\n",
    "processor.clear_directory(test)\n",
    "### CAREFUL \n",
    "\n",
    "processor.generate_train_test()\n",
    "# this is 5,000 samples * num times in samples (10 in the case of 100 timebins in 1000 timebin segment)\n",
    "processor.generate_embedding(samples=5e3, time_bins_per_sample=100, reduction_dims=2)\n",
    "processor.plot_embedding_and_labels()\n",
    "processor.generate_train_test_labels(reduce=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_class import SongDataSet_Image, plot_spectrogram_and_labels\n",
    "\n",
    "train_dir = \"train\"\n",
    "test_dir = \"test\"\n",
    "\n",
    "train_dataset = SongDataSet_Image(train_dir)\n",
    "test_dataset = SongDataSet_Image(test_dir)\n",
    "train_loader = DataLoader(train_dataset, batch_size=24, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Get a batch of data\n",
    "spec, psuedo_labels, ground_truth_labels = next(iter(train_loader))\n",
    "\n",
    "# Plotting\n",
    "spec = spec[0].squeeze(0)  # If your data is batched, get the first item\n",
    "plot_spectrogram_and_labels(spec, ground_truth_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "from model import TweetyBERT\n",
    "\n",
    "def detailed_count_parameters(model):\n",
    "    \"\"\"Print details of layers with the number of trainable parameters in the model.\"\"\"\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        total_params += param\n",
    "        # print(f\"Layer: {name} | Parameters: {param:,} | Shape: {list(parameter.shape)}\")\n",
    "    print(f\"\\nTotal Trainable Parameters: {total_params:,}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "model = TweetyBERT(d_transformer=64, nhead_transformer=2, embedding_dim=100, num_labels=100, tau=1, dropout=0.1, dim_feedforward=64, transformer_layers=2, reduced_embedding= 27)\n",
    "detailed_count_parameters(model)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import ModelTrainer\n",
    "\n",
    "# Usage:\n",
    "trainer = ModelTrainer(model, train_loader, test_loader, optimizer, device, max_steps=1001, eval_interval=5e1, save_interval=500)\n",
    "trainer.train()\n",
    "trainer.plot_results()\n",
    "print(f\"final loss {trainer.loss_list[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import TweetyBERTAnalysis\n",
    "\n",
    "analysis = TweetyBERTAnalysis(train_loader, model, device)\n",
    "\n",
    "# Fit k-means to initialize the kmeans attribute\n",
    "analysis.fit_kmeans()\n",
    "# Now, collect the data\n",
    "analysis.collect_data()\n",
    "# Calculate the F1 score\n",
    "f1 = analysis.calculate_f1_score()\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_functions import replace_short_sequences, pad_and_relabel, plot_spectrogram_and_labels\n",
    "\n",
    "#### 1 should always be non-song, and 0 should always be song #### Thats why I will generate an empty spectogram and see the labels and invert them if they are wrong\n",
    "test = np.zeros((1, 492, 286))\n",
    "test = torch.Tensor(test)\n",
    "output_test, _ = model.inference_forward(test.unsqueeze(0).to(device))\n",
    "labels_test = kmeans.predict(output_test[0].detach().cpu().numpy())\n",
    "\n",
    "if labels_test.all() == 1:\n",
    "    invert_labels = False \n",
    "else:\n",
    "    invert_labels = True \n",
    "\n",
    "\n",
    "for i, file in enumerate(os.listdir(\"/home/george-vengrovski/Documents/canary_song_detector/data/\")):\n",
    "    f = np.load(os.path.join(data_root, file))\n",
    "    spectogram = f['s']\n",
    "    spectogram = spectogram[8:500,:]\n",
    "    # Normalize (Z-score normalization)\n",
    "    mean = spectogram.mean()\n",
    "    std = spectogram.std()\n",
    "    spectogram = (spectogram - mean) / (std + 1e-7)  # Adding a small constant to prevent division by zero\n",
    "\n",
    "    # Replace NaN values with zeros\n",
    "    spectogram[np.isnan(spectogram)] = 0\n",
    "    spectogram = torch.from_numpy(spectogram).float().unsqueeze(0)\n",
    "    output, _ = model.inference_forward(spectogram.unsqueeze(0).to(device))\n",
    "\n",
    "    labels = kmeans.predict(output[0].detach().cpu().numpy())\n",
    "    \n",
    "    if invert_labels:\n",
    "        # invert labels \n",
    "        labels = (1-labels)\n",
    "\n",
    "    # the order of below functions is important, 1 is NOT SONG \n",
    "    labels = replace_short_sequences(labels, target_label=1, min_length=50)\n",
    "    labels = replace_short_sequences(labels, target_label=0, min_length=200)\n",
    "\n",
    "    # pad song\n",
    "    labels = pad_and_relabel(labels, target_label=0, n=50)\n",
    "\n",
    "    \n",
    "    plot_spectrogram_and_labels(f['s'], labels)\n",
    "\n",
    "    if i > 5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canary-vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
