{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms \n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.signal import spectrogram\n",
    "from scipy.fftpack import dst, dct\n",
    "\n",
    "songs = '/home/george-vengrovski/Documents/canary_song_detector/sample_songs'\n",
    "not_songs = '/home/george-vengrovski/Documents/canary_song_detector/sample_not_songs'\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "def train_test_split(train_split=0.8):\n",
    "    # Create directories if not already created\n",
    "    if not os.path.exists('test'):\n",
    "        os.makedirs('test')\n",
    "\n",
    "    if not os.path.exists('train'):\n",
    "        os.makedirs('train')\n",
    "\n",
    "    # Get a list of all song files and non-song files\n",
    "    songs = glob.glob('/home/george-vengrovski/Documents/canary_song_detector/sample_songs/*.wav')\n",
    "    not_songs = glob.glob('/home/george-vengrovski/Documents/canary_song_detector/sample_not_songs/*.wav')\n",
    "\n",
    "    # Split songs into train and test sets\n",
    "    train_songs = songs[:int(len(songs) * train_split)]\n",
    "    test_songs = songs[int(len(songs) * train_split):]\n",
    "\n",
    "    # Copy song files into train and test directories with updated filenames\n",
    "    for song in train_songs:\n",
    "        file_name = os.path.basename(song)\n",
    "        new_file_name = os.path.splitext(file_name)[0] + '_song.wav'\n",
    "        shutil.copy(song, os.path.join('train', new_file_name))\n",
    "\n",
    "    for song in test_songs:\n",
    "        file_name = os.path.basename(song)\n",
    "        new_file_name = os.path.splitext(file_name)[0] + '_song.wav'\n",
    "        shutil.copy(song, os.path.join('test', new_file_name))\n",
    "\n",
    "    # Split non-song files into train and test sets\n",
    "    train_not_songs = not_songs[:int(len(not_songs) * train_split)]\n",
    "    test_not_songs = not_songs[int(len(not_songs) * train_split):]\n",
    "\n",
    "    # Copy non-song files into train and test directories with updated filenames\n",
    "    for not_song in train_not_songs:\n",
    "        file_name = os.path.basename(not_song)\n",
    "        new_file_name = os.path.splitext(file_name)[0] + '_not_song.wav'\n",
    "        shutil.copy(not_song, os.path.join('train', new_file_name))\n",
    "\n",
    "    for not_song in test_not_songs:\n",
    "        file_name = os.path.basename(not_song)\n",
    "        new_file_name = os.path.splitext(file_name)[0] + '_not_song.wav'\n",
    "        shutil.copy(not_song, os.path.join('test', new_file_name))\n",
    "        \n",
    "train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class DataSet(Dataset):\n",
    "    def __init__(self, type):\n",
    "        self.labels = []\n",
    "        self.waveforms = [] \n",
    "        '''\n",
    "        Purpose:\n",
    "        - Loads song, converts to waveform, converts three different periodicties and power\n",
    "        - Labels song as 1 and not song as 0 \n",
    "        '''\n",
    "        \n",
    "        folder = 'train' if type == 'train' else 'test' \n",
    "\n",
    "        for file in glob.glob(folder + '/*.wav'):\n",
    "            waveform, sample_rate = torchaudio.load(file)\n",
    "            # Normalize the waveform\n",
    "            mean = waveform.mean()\n",
    "            std = waveform.std()\n",
    "            waveform = (waveform - mean) / std\n",
    "            self.waveforms.append(waveform)\n",
    "            self.labels.append(0 if 'not_song' in file else 1)\n",
    "\n",
    "        ## Check precentage of songs and not songs, remove some if not 50/50\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        waveform = self.waveforms[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return waveform, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.waveforms)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        waveforms, labels = zip(*batch)\n",
    "\n",
    "        # Pad the waveforms\n",
    "        waveforms = pad_sequence([torch.flatten(w) for w in waveforms], batch_first=True)\n",
    "        \n",
    "        return waveforms, labels\n",
    "    \n",
    "\n",
    "train_dataset = DataSet(type='train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "\n",
    "test_dataset = DataSet(type='test')\n",
    "test_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=train_dataset.collate_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier Architecture \n",
    "- 4 1d conv layers for the waveform of the periodicities, and amplitude \n",
    "- LSTM layers afterwards \n",
    "- Fully connected layer with two nodes for song v non-song "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_extractor_dim, hidden_size, num_layers):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        # Feature extractor\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=feature_extractor_dim, kernel_size=10, padding=1, stride=5)\n",
    "        self.conv2 = nn.Conv1d(in_channels=feature_extractor_dim, out_channels=feature_extractor_dim, kernel_size=3, padding=1, stride=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=feature_extractor_dim, out_channels=feature_extractor_dim, kernel_size=3, padding=1, stride=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=feature_extractor_dim, out_channels=feature_extractor_dim, kernel_size=3, padding=1, stride=2)\n",
    "        self.conv5 = nn.Conv1d(in_channels=feature_extractor_dim, out_channels=feature_extractor_dim, kernel_size=3, padding=1, stride=2)\n",
    "        self.conv6 = nn.Conv1d(in_channels=feature_extractor_dim, out_channels=feature_extractor_dim, kernel_size=2, padding=1, stride=2)\n",
    "        self.conv7 = nn.Conv1d(in_channels=feature_extractor_dim, out_channels=feature_extractor_dim, kernel_size=2, padding=1, stride=2)\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size=feature_extractor_dim, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Fully connected layer \n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "\n",
    "        # Reshape for GRU\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # x is the output for each timestep of the GRU while h is the final hidden state\n",
    "        x, h = self.gru(x)\n",
    "\n",
    "        # x = self.fc1(F.relu(h))\n",
    "        # x = self.fc2(F.relu(x))\n",
    "        x = self.fc3(F.relu(h))\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        x = x.squeeze(0)\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "waveform, labels = next(iter(train_loader))\n",
    "\n",
    "# # switch first and second dim\n",
    "# waveform = waveform.transpose(1,2)\n",
    "\n",
    "waveform = waveform.unsqueeze(1)\n",
    "\n",
    "model = Classifier(feature_extractor_dim=64, hidden_size=200, num_layers=1)\n",
    "print(model.forward(waveform).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 78,177 trainable parameters\n",
      "Epoch [1/100], Train Loss: 0.7136, Train Accuracy: 80.45%\n",
      "Epoch [1/100], Test Loss: 0.7118, Test Accuracy: 80.45%\n",
      "Epoch [2/100], Train Loss: 0.7095, Train Accuracy: 80.45%\n",
      "Epoch [2/100], Test Loss: 0.7086, Test Accuracy: 80.45%\n",
      "Epoch [3/100], Train Loss: 0.7071, Train Accuracy: 80.45%\n",
      "Epoch [3/100], Test Loss: 0.7056, Test Accuracy: 80.45%\n",
      "Epoch [4/100], Train Loss: 0.7040, Train Accuracy: 80.45%\n",
      "Epoch [4/100], Test Loss: 0.7020, Test Accuracy: 80.45%\n",
      "Epoch [5/100], Train Loss: 0.7007, Train Accuracy: 80.45%\n",
      "Epoch [5/100], Test Loss: 0.6990, Test Accuracy: 80.45%\n",
      "Epoch [6/100], Train Loss: 0.6972, Train Accuracy: 80.45%\n",
      "Epoch [6/100], Test Loss: 0.6953, Test Accuracy: 80.45%\n",
      "Epoch [7/100], Train Loss: 0.6934, Train Accuracy: 80.45%\n",
      "Epoch [7/100], Test Loss: 0.6909, Test Accuracy: 80.45%\n",
      "Epoch [8/100], Train Loss: 0.6883, Train Accuracy: 80.45%\n",
      "Epoch [8/100], Test Loss: 0.6858, Test Accuracy: 80.45%\n",
      "Epoch [9/100], Train Loss: 0.6844, Train Accuracy: 80.45%\n",
      "Epoch [9/100], Test Loss: 0.6816, Test Accuracy: 80.45%\n",
      "Epoch [10/100], Train Loss: 0.6799, Train Accuracy: 80.45%\n",
      "Epoch [10/100], Test Loss: 0.6770, Test Accuracy: 80.45%\n",
      "Epoch [11/100], Train Loss: 0.6738, Train Accuracy: 80.45%\n",
      "Epoch [11/100], Test Loss: 0.6699, Test Accuracy: 80.45%\n",
      "Epoch [12/100], Train Loss: 0.6635, Train Accuracy: 80.45%\n",
      "Epoch [12/100], Test Loss: 0.6563, Test Accuracy: 80.45%\n",
      "Epoch [13/100], Train Loss: 0.6466, Train Accuracy: 80.45%\n",
      "Epoch [13/100], Test Loss: 0.6375, Test Accuracy: 80.45%\n",
      "Epoch [14/100], Train Loss: 0.6224, Train Accuracy: 80.45%\n",
      "Epoch [14/100], Test Loss: 0.6144, Test Accuracy: 80.45%\n",
      "Epoch [15/100], Train Loss: 0.5947, Train Accuracy: 80.45%\n",
      "Epoch [15/100], Test Loss: 0.5793, Test Accuracy: 80.45%\n",
      "Epoch [16/100], Train Loss: 0.5711, Train Accuracy: 80.45%\n",
      "Epoch [16/100], Test Loss: 0.5608, Test Accuracy: 80.45%\n",
      "Epoch [17/100], Train Loss: 0.5641, Train Accuracy: 80.45%\n",
      "Epoch [17/100], Test Loss: 0.5491, Test Accuracy: 80.45%\n",
      "Epoch [18/100], Train Loss: 0.5467, Train Accuracy: 80.45%\n",
      "Epoch [18/100], Test Loss: 0.5426, Test Accuracy: 80.45%\n",
      "Epoch [19/100], Train Loss: 0.5383, Train Accuracy: 80.45%\n",
      "Epoch [19/100], Test Loss: 0.5483, Test Accuracy: 80.45%\n",
      "Epoch [20/100], Train Loss: 0.5355, Train Accuracy: 80.45%\n",
      "Epoch [20/100], Test Loss: 0.5354, Test Accuracy: 80.45%\n",
      "Epoch [21/100], Train Loss: 0.5327, Train Accuracy: 80.45%\n",
      "Epoch [21/100], Test Loss: 0.5317, Test Accuracy: 80.45%\n",
      "Epoch [22/100], Train Loss: 0.5301, Train Accuracy: 80.45%\n",
      "Epoch [22/100], Test Loss: 0.5297, Test Accuracy: 80.45%\n",
      "Epoch [23/100], Train Loss: 0.5279, Train Accuracy: 80.45%\n",
      "Epoch [23/100], Test Loss: 0.5270, Test Accuracy: 80.45%\n",
      "Epoch [24/100], Train Loss: 0.5274, Train Accuracy: 80.45%\n",
      "Epoch [24/100], Test Loss: 0.5278, Test Accuracy: 80.45%\n",
      "Epoch [25/100], Train Loss: 0.5358, Train Accuracy: 80.45%\n",
      "Epoch [25/100], Test Loss: 0.5256, Test Accuracy: 80.45%\n",
      "Epoch [26/100], Train Loss: 0.5354, Train Accuracy: 80.45%\n",
      "Epoch [26/100], Test Loss: 0.5216, Test Accuracy: 80.45%\n",
      "Epoch [27/100], Train Loss: 0.5321, Train Accuracy: 80.45%\n",
      "Epoch [27/100], Test Loss: 0.5163, Test Accuracy: 80.45%\n",
      "Epoch [28/100], Train Loss: 0.5144, Train Accuracy: 80.45%\n",
      "Epoch [28/100], Test Loss: 0.5256, Test Accuracy: 80.45%\n",
      "Epoch [29/100], Train Loss: 0.5121, Train Accuracy: 80.45%\n",
      "Epoch [29/100], Test Loss: 0.5232, Test Accuracy: 80.45%\n",
      "Epoch [30/100], Train Loss: 0.5107, Train Accuracy: 80.45%\n",
      "Epoch [30/100], Test Loss: 0.5224, Test Accuracy: 80.45%\n",
      "Epoch [31/100], Train Loss: 0.5084, Train Accuracy: 80.45%\n",
      "Epoch [31/100], Test Loss: 0.5072, Test Accuracy: 80.45%\n",
      "Epoch [32/100], Train Loss: 0.5077, Train Accuracy: 80.45%\n",
      "Epoch [32/100], Test Loss: 0.5085, Test Accuracy: 80.45%\n",
      "Epoch [33/100], Train Loss: 0.5078, Train Accuracy: 80.45%\n",
      "Epoch [33/100], Test Loss: 0.5198, Test Accuracy: 80.45%\n",
      "Epoch [34/100], Train Loss: 0.5072, Train Accuracy: 80.45%\n",
      "Epoch [34/100], Test Loss: 0.5068, Test Accuracy: 80.45%\n",
      "Epoch [35/100], Train Loss: 0.5053, Train Accuracy: 80.45%\n",
      "Epoch [35/100], Test Loss: 0.5062, Test Accuracy: 80.45%\n",
      "Epoch [36/100], Train Loss: 0.5061, Train Accuracy: 80.45%\n",
      "Epoch [36/100], Test Loss: 0.5056, Test Accuracy: 80.45%\n",
      "Epoch [37/100], Train Loss: 0.5015, Train Accuracy: 80.45%\n",
      "Epoch [37/100], Test Loss: 0.4999, Test Accuracy: 80.45%\n",
      "Epoch [38/100], Train Loss: 0.4980, Train Accuracy: 80.45%\n",
      "Epoch [38/100], Test Loss: 0.4981, Test Accuracy: 80.45%\n",
      "Epoch [39/100], Train Loss: 0.4989, Train Accuracy: 80.45%\n",
      "Epoch [39/100], Test Loss: 0.5120, Test Accuracy: 80.45%\n",
      "Epoch [40/100], Train Loss: 0.4985, Train Accuracy: 80.45%\n",
      "Epoch [40/100], Test Loss: 0.4962, Test Accuracy: 80.45%\n",
      "Epoch [41/100], Train Loss: 0.4963, Train Accuracy: 80.45%\n",
      "Epoch [41/100], Test Loss: 0.4960, Test Accuracy: 80.45%\n",
      "Epoch [42/100], Train Loss: 0.5106, Train Accuracy: 80.45%\n",
      "Epoch [42/100], Test Loss: 0.4961, Test Accuracy: 80.45%\n",
      "Epoch [43/100], Train Loss: 0.4963, Train Accuracy: 80.45%\n",
      "Epoch [43/100], Test Loss: 0.4955, Test Accuracy: 80.45%\n",
      "Epoch [44/100], Train Loss: 0.4957, Train Accuracy: 80.45%\n",
      "Epoch [44/100], Test Loss: 0.5096, Test Accuracy: 80.45%\n",
      "Epoch [45/100], Train Loss: 0.5120, Train Accuracy: 80.45%\n",
      "Epoch [45/100], Test Loss: 0.4952, Test Accuracy: 80.45%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     32\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, label\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m))\n\u001b[0;32m---> 33\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()  \u001b[39m# compute the gradients\u001b[39;00m\n\u001b[1;32m     34\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     36\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/canary-vae/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/canary-vae/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.00001\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Classifier(feature_extractor_dim=64, hidden_size=32, num_layers=1).to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for waveform, label in train_loader:\n",
    "        waveform = waveform.unsqueeze(1).to(device)\n",
    "        label = torch.tensor(label).to(device)\n",
    "        output = model(waveform)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        train_total += label.size(0)\n",
    "        train_correct += (predicted == label).sum().item()\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, label.unsqueeze(1))\n",
    "        loss.backward()  # compute the gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    print ('Epoch [{}/{}], Train Loss: {:.4f}, Train Accuracy: {:.2f}%'.format(epoch+1, epochs, train_loss / len(train_loader), train_accuracy))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss = 0\n",
    "        for waveform, label in test_loader:\n",
    "            waveform = waveform.unsqueeze(1).to(device)\n",
    "            label = torch.tensor(label).to(device)\n",
    "            output = model(waveform)\n",
    "\n",
    "            test_loss += criterion(output, label.unsqueeze(1)).item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "\n",
    "        print('Epoch [{}/{}], Test Loss: {:.4f}, Test Accuracy: {:.2f}%'.format(\n",
    "            epoch+1, epochs, test_loss / len(test_loader), (correct / total) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAx6UlEQVR4nO3deVyU5f7/8Tc7CgLiAlnuWYp7rmRlKoqKldspO2XgMS1Dc+lrZqdcKLOsFNeszjlimWV6ysrSVNxKyQyP5l6WWxKgGYxLgsD9+6MH83MEFGFk8Or1fDzm8XCu+7rv+3PfzMibe67rHjfLsiwBAAAYyt3VBQAAAFxLhB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHVw3Jk2aJDc3tzLZ19133627777b/nzDhg1yc3PTsmXLymT/MTExqlOnTpnsq6TOnDmjRx99VKGhoXJzc9OoUaPKZL8xMTHy9/d36jYv/XmX1OHDh+Xm5qaEhIRSb6ssubm5adKkSSVat06dOoqJiXFqPYCzEXbgEgkJCXJzc7M/fH19VaNGDUVGRmrWrFk6ffq0U/aTkpKiSZMmaceOHU7ZnjOV59qK46WXXlJCQoKGDRumd999VwMHDiyyb506ddSrV68yrO76d+l7pKhHeQ/F19LF58HT01PBwcFq1aqVRo4cqb1795Z4u+fOndOkSZO0YcMG5xULl/J0dQH4a4uLi1PdunV14cIFpaamasOGDRo1apSmT5+uTz/9VM2aNbP3fe655/TMM89c1fZTUlI0efJk1alTRy1atCj2eqtXr76q/ZTE5Wp7++23lZeXd81rKI1169apffv2mjhxoqtLKTdq166tP/74Q15eXqXe1l133aV3333Xoe3RRx9V27ZtNXToUHubM65y/fHHH/L0LNmvgwMHDsjd3XV/N3ft2lWPPPKILMtSZmamdu7cqYULF2revHl65ZVXNGbMmKve5rlz5zR58mRJcsoVP7geYQcu1aNHD7Vu3dr+fPz48Vq3bp169eqle++9V/v27VOFChUkSZ6eniX+D7m4zp07p4oVK8rb2/ua7udKnPHL8lpLT09XWFiYq8soV/KvUjpDvXr1VK9ePYe2xx9/XPXq1dPDDz9c5Ho5OTnKy8u7qtdwaWr28fEp8brOcMsttxQ4Hy+//LLuuecePfXUU2rYsKF69uzpoupQXvAxFsqdzp076/nnn9eRI0e0aNEie3thY3bWrFmjO+64Q0FBQfL399ett96qZ599VtKf42zatGkjSRo0aJD9cnf+eIq7775bTZo0UXJysu666y5VrFjRvm5RYzhyc3P17LPPKjQ0VH5+frr33nt17Ngxhz5FjWG4eJtXqq2wMTtnz57VU089pZo1a8rHx0e33nqrXnvtNVmW5dDPzc1Nw4cP1/Lly9WkSRP5+PiocePGWrVqVeEn/BLp6ekaPHiwQkJC5Ovrq+bNm2vhwoX25fnjlw4dOqTPP//cXvvhw4eLtf2ifPXVV/rb3/6mWrVqycfHRzVr1tTo0aP1xx9/FNr/559/VmRkpPz8/FSjRg3FxcUVOBd5eXmKj49X48aN5evrq5CQED322GP6/fffr1jP7Nmz1bhxY1WsWFGVK1dW69attXjx4suuU9iYnfwxRsePH1fv3r3l7++vatWq6f/+7/+Um5t75RNTjP299tprio+PV/369eXj46O9e/cqOztbEyZMUKtWrRQYGCg/Pz/deeedWr9+fYHtXDpmJ/+9dvDgQcXExCgoKEiBgYEaNGiQzp0757Dupa/3/I/fNm/erDFjxqhatWry8/NTnz59dOLECYd18/LyNGnSJNWoUUMVK1ZUp06dtHfv3lKPA6pSpYo++OADeXp6asqUKfb24pyTw4cPq1q1apKkyZMn21/f+efn+++/V0xMjOrVqydfX1+FhobqH//4h3777bcS14trjys7KJcGDhyoZ599VqtXr9aQIUMK7bNnzx716tVLzZo1U1xcnHx8fHTw4EFt3rxZktSoUSPFxcVpwoQJGjp0qO68805J0u23327fxm+//aYePXpowIABevjhhxUSEnLZuqZMmSI3NzeNGzdO6enpio+PV0REhHbs2GG/AlUcxantYpZl6d5779X69es1ePBgtWjRQl9++aXGjh2r48ePa8aMGQ79v/76a3300Ud64oknVKlSJc2aNUv9+vXT0aNHVaVKlSLr+uOPP3T33Xfr4MGDGj58uOrWraulS5cqJiZGGRkZGjlypBo1aqR3331Xo0eP1k033aSnnnpKkuy/IEpq6dKlOnfunIYNG6YqVaro22+/1ezZs/XLL79o6dKlDn1zc3PVvXt3tW/fXtOmTdOqVas0ceJE5eTkKC4uzt7vscceU0JCggYNGqQnn3xShw4d0pw5c/S///1PmzdvLvIK2ttvv60nn3xS/fv318iRI3X+/Hl9//332rp1q/7+979f9bHl5uYqMjJS7dq102uvvaa1a9fq9ddfV/369TVs2LCr3t6lFixYoPPnz2vo0KHy8fFRcHCwbDab/vWvf+nBBx/UkCFDdPr0af373/9WZGSkvv3222J9rHv//ferbt26mjp1qrZv365//etfql69ul555ZUrrjtixAhVrlxZEydO1OHDhxUfH6/hw4dryZIl9j7jx4/XtGnTdM899ygyMlI7d+5UZGSkzp8/X5rTIUmqVauWOnbsqPXr18tmsykgIKBY56RatWp64403NGzYMPXp00d9+/aVJPtH6mvWrNHPP/+sQYMGKTQ0VHv27NFbb72lPXv26JtvvimzSRS4ShbgAgsWLLAkWdu2bSuyT2BgoNWyZUv784kTJ1oXv2RnzJhhSbJOnDhR5Da2bdtmSbIWLFhQYFnHjh0tSdb8+fMLXdaxY0f78/Xr11uSrBtvvNGy2Wz29g8//NCSZM2cOdPeVrt2bSs6OvqK27xcbdHR0Vbt2rXtz5cvX25Jsl588UWHfv3797fc3NysgwcP2tskWd7e3g5tO3futCRZs2fPLrCvi8XHx1uSrEWLFtnbsrOzrfDwcMvf39/h2GvXrm1FRUVddntX0/fcuXMF2qZOnWq5ublZR44csbdFR0dbkqwRI0bY2/Ly8qyoqCjL29vb/nr46quvLEnWe++957DNVatWFWi/9Gdz3333WY0bNy7WsV3s0KFDBX6m+fXGxcU59G3ZsqXVqlWrq9q+n5+fw2srf38BAQFWenq6Q9+cnBwrKyvLoe3333+3QkJCrH/84x8O7ZKsiRMn2p/nv9cu7denTx+rSpUqDm2Xvt7z39sRERFWXl6evX306NGWh4eHlZGRYVmWZaWmplqenp5W7969HbY3adIkS1Kh76FLSbJiY2OLXD5y5EhLkrVz507Lsop/Tk6cOFHgnOQr7HX6/vvvW5KsTZs2XbFmuAYfY6Hc8vf3v+ysrKCgIEnSJ598UuLBvD4+Pho0aFCx+z/yyCOqVKmS/Xn//v11ww036IsvvijR/ovriy++kIeHh5588kmH9qeeekqWZWnlypUO7REREapfv779ebNmzRQQEKCff/75ivsJDQ3Vgw8+aG/z8vLSk08+qTNnzmjjxo1OOJrCXXxl7OzZszp58qRuv/12WZal//3vfwX6Dx8+3P7v/I/usrOztXbtWkl/XikKDAxU165ddfLkSfujVatW8vf3L/TjnHxBQUH65ZdftG3bNqcd3+OPP+7w/M4777ziz6O4+vXrV+DKmoeHh33cTl5enk6dOqWcnBy1bt1a27dvL3HNv/32m2w22xXXHTp0qMNVjjvvvFO5ubk6cuSIJCkxMVE5OTl64oknHNYbMWJEsWorjvzB2/n/jzjjnFz8Oj1//rxOnjyp9u3bS1Kxt4GyR9hBuXXmzBmHYHGpBx54QB06dNCjjz6qkJAQDRgwQB9++OFVBZ8bb7zxqgZyNmjQwOG5m5ubbr755lKPV7mSI0eOqEaNGgXOR6NGjezLL1arVq0C26hcufIVx6ocOXJEDRo0KDC7pqj9ONPRo0cVExOj4OBg+7iWjh07SpIyMzMd+rq7uxcYvHvLLbdIkv1n8eOPPyozM1PVq1dXtWrVHB5nzpxRenp6kbWMGzdO/v7+atu2rRo0aKDY2Fj7x6Ml4evrWyCMFOfnUVx169YttH3hwoVq1qyZfH19VaVKFVWrVk2ff/55gfNZlEtfR5UrV5akYtV9pXXzX0s333yzQ7/g4GB739I6c+aMJDm8b0p7Tk6dOqWRI0cqJCREFSpUULVq1eznv7jbQNljzA7KpV9++UWZmZkF/iO8WIUKFbRp0yatX79en3/+uVatWqUlS5aoc+fOWr16tTw8PK64n6sZZ1NcRX1mn5ubW6yanKGo/ViXDOAtL3Jzc9W1a1edOnVK48aNU8OGDeXn56fjx48rJiamRFfu8vLyVL16db333nuFLr/cGKNGjRrpwIEDWrFihVatWqX//ve/mjdvniZMmGCfknw1rvXPvbDX8aJFixQTE6PevXtr7Nixql69ujw8PDR16lT99NNPxdpuaV5H5eE1uHv3bnl4eNjDiDPOyf33368tW7Zo7NixatGihfz9/ZWXl6fu3buX+9tF/JURdlAu5d9fJDIy8rL93N3d1aVLF3Xp0kXTp0/XSy+9pH/+859av369IiIinD5Y8Mcff3R4blmWDh486HA/oMqVKysjI6PAukeOHHG4GnE1tdWuXVtr167V6dOnHf5K3b9/v325M9SuXVvff/+98vLyHK7uOHs/l9q1a5d++OEHLVy4UI888oi9fc2aNYX2z8vL088//2y/miNJP/zwgyTZZ7HVr19fa9euVYcOHUoUav38/PTAAw/ogQceUHZ2tvr27aspU6Zo/PjxTptefi0tW7ZM9erV00cffeTwWisv90XKfy0dPHjQ4crUb7/95pQrXkePHtXGjRsVHh5uf88U95wU9d78/ffflZiYqMmTJ2vChAn29kv/X0D5w8dYKHfWrVunF154QXXr1tVDDz1UZL9Tp04VaMufYZKVlSXpz19YkgoNHyXxzjvvOIwjWrZsmX799Vf16NHD3la/fn198803ys7OtretWLGiwBT1q6mtZ8+eys3N1Zw5cxzaZ8yYITc3N4f9l0bPnj2VmprqMGMmJydHs2fPlr+/v/1jJWfLvwpw8V/9lmVp5syZRa5z8bmwLEtz5syRl5eXunTpIunPv8Bzc3P1wgsvFFg3Jyfnsuf90mnE3t7eCgsLk2VZunDhQrGOydUKO6dbt25VUlKSq0py0KVLF3l6euqNN95waL/0NV4Sp06d0oMPPqjc3Fz985//tLcX95xUrFhRUsH3ZmHrS1J8fHypa8a1xZUduNTKlSu1f/9+5eTkKC0tTevWrdOaNWtUu3Ztffrpp5f9CzouLk6bNm1SVFSUateurfT0dM2bN0833XST7rjjDkl/Bo+goCDNnz9flSpVkp+fn9q1a1fkGIcrCQ4O1h133KFBgwYpLS1N8fHxuvnmmx2mxz/66KNatmyZunfvrvvvv18//fSTFi1a5DBg+Gpru+eee9SpUyf985//1OHDh9W8eXOtXr1an3zyiUaNGlVg2yU1dOhQvfnmm4qJiVFycrLq1KmjZcuWafPmzYqPj7/sGKorOXjwoF588cUC7S1btlS3bt1Uv359/d///Z+OHz+ugIAA/fe//y3yL3xfX1+tWrVK0dHRateunVauXKnPP/9czz77rP3jqY4dO+qxxx7T1KlTtWPHDnXr1k1eXl768ccftXTpUs2cOVP9+/cvdPvdunVTaGioOnTooJCQEO3bt09z5sxRVFRUqc5BWerVq5c++ugj9enTR1FRUTp06JDmz5+vsLAw+1gWVwoJCdHIkSP1+uuv695771X37t21c+dOrVy5UlWrVi32lc8ffvhBixYtkmVZstls2rlzp5YuXaozZ85o+vTp6t69u71vcc9JhQoVFBYWpiVLluiWW25RcHCwmjRpoiZNmuiuu+7StGnTdOHCBd14441avXq1Dh065PTzAydzxRQwIH96av7D29vbCg0Ntbp27WrNnDnTYYpzvkunnicmJlr33XefVaNGDcvb29uqUaOG9eCDD1o//PCDw3qffPKJFRYWZnl6ejpMC+7YsWOR04uLmnr+/vvvW+PHj7eqV69uVahQwYqKinKYFp3v9ddft2688UbLx8fH6tChg/Xdd98V2Oblart06rllWdbp06et0aNHWzVq1LC8vLysBg0aWK+++qrD9F7LKno6blFT4i+VlpZmDRo0yKpatarl7e1tNW3atNDp8Vc79fzin/fFj8GDB1uWZVl79+61IiIiLH9/f6tq1arWkCFD7FPmL53K7efnZ/30009Wt27drIoVK1ohISHWxIkTrdzc3AL7fuutt6xWrVpZFSpUsCpVqmQ1bdrUevrpp62UlBR7n0t/Nm+++aZ11113WVWqVLF8fHys+vXrW2PHjrUyMzMve5xFTT338/Mr0PfS13NxFDX1/NVXXy3QNy8vz3rppZes2rVrWz4+PlbLli2tFStWFPraUhFTzy+9rUP++/bQoUP2tqKmnl96W4n899D69evtbTk5Odbzzz9vhYaGWhUqVLA6d+5s7du3z6pSpYr1+OOPX/F8XPw6cnd3t4KCgqyWLVtaI0eOtPbs2VOqc7JlyxarVatWlre3t8P5+eWXX6w+ffpYQUFBVmBgoPW3v/3NSklJKXKqOsoHN8sqpyMWAQB/ORkZGapcubJefPFFh4+ggNJgzA4AwCUK+yqQ/PEvfAEnnIkxOwAAl1iyZIkSEhLUs2dP+fv76+uvv9b777+vbt26qUOHDq4uDwYh7AAAXKJZs2by9PTUtGnTZLPZ7IOWCxvIDpQGY3YAAIDRGLMDAACMRtgBAABGY8yO/rz1fEpKiipVquT0rxcAAADXhmVZOn36tGrUqFHgC4wvRtiRlJKSopo1a7q6DAAAUALHjh3TTTfdVORywo5kv/37sWPHFBAQ4OJqAABAcdhsNtWsWfOKX+NC2NH//4bbgIAAwg4AANeZKw1BYYAyAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGieri7AdHWe+dzVJQDl2uGXo1xdAgDDcWUHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0cpN2Hn55Zfl5uamUaNG2dvOnz+v2NhYValSRf7+/urXr5/S0tIc1jt69KiioqJUsWJFVa9eXWPHjlVOTk4ZVw8AAMqrchF2tm3bpjfffFPNmjVzaB89erQ+++wzLV26VBs3blRKSor69u1rX56bm6uoqChlZ2dry5YtWrhwoRISEjRhwoSyPgQAAFBOuTzsnDlzRg899JDefvttVa5c2d6emZmpf//735o+fbo6d+6sVq1aacGCBdqyZYu++eYbSdLq1au1d+9eLVq0SC1atFCPHj30wgsvaO7cucrOznbVIQEAgHLE5WEnNjZWUVFRioiIcGhPTk7WhQsXHNobNmyoWrVqKSkpSZKUlJSkpk2bKiQkxN4nMjJSNptNe/bsKXKfWVlZstlsDg8AAGAmT1fu/IMPPtD27du1bdu2AstSU1Pl7e2toKAgh/aQkBClpqba+1wcdPKX5y8rytSpUzV58uRSVg8AAK4HLruyc+zYMY0cOVLvvfeefH19y3Tf48ePV2Zmpv1x7NixMt0/AAAoOy4LO8nJyUpPT9dtt90mT09PeXp6auPGjZo1a5Y8PT0VEhKi7OxsZWRkOKyXlpam0NBQSVJoaGiB2Vn5z/P7FMbHx0cBAQEODwAAYCaXhZ0uXbpo165d2rFjh/3RunVrPfTQQ/Z/e3l5KTEx0b7OgQMHdPToUYWHh0uSwsPDtWvXLqWnp9v7rFmzRgEBAQoLCyvzYwIAAOWPy8bsVKpUSU2aNHFo8/PzU5UqVeztgwcP1pgxYxQcHKyAgACNGDFC4eHhat++vSSpW7duCgsL08CBAzVt2jSlpqbqueeeU2xsrHx8fMr8mAAAQPnj0gHKVzJjxgy5u7urX79+ysrKUmRkpObNm2df7uHhoRUrVmjYsGEKDw+Xn5+foqOjFRcX58KqAQBAeeJmWZbl6iJczWazKTAwUJmZmU4fv1Pnmc+duj3ANIdfjnJ1CQCuU8X9/e3y++wAAABcS4QdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARnNp2HnjjTfUrFkzBQQEKCAgQOHh4Vq5cqV9+fnz5xUbG6sqVarI399f/fr1U1pamsM2jh49qqioKFWsWFHVq1fX2LFjlZOTU9aHAgAAyimXhp2bbrpJL7/8spKTk/Xdd9+pc+fOuu+++7Rnzx5J0ujRo/XZZ59p6dKl2rhxo1JSUtS3b1/7+rm5uYqKilJ2dra2bNmihQsXKiEhQRMmTHDVIQEAgHLGzbIsy9VFXCw4OFivvvqq+vfvr2rVqmnx4sXq37+/JGn//v1q1KiRkpKS1L59e61cuVK9evVSSkqKQkJCJEnz58/XuHHjdOLECXl7exdrnzabTYGBgcrMzFRAQIBTj6fOM587dXuAaQ6/HOXqEgBcp4r7+7vcjNnJzc3VBx98oLNnzyo8PFzJycm6cOGCIiIi7H0aNmyoWrVqKSkpSZKUlJSkpk2b2oOOJEVGRspms9mvDhUmKytLNpvN4QEAAMzk8rCza9cu+fv7y8fHR48//rg+/vhjhYWFKTU1Vd7e3goKCnLoHxISotTUVElSamqqQ9DJX56/rChTp05VYGCg/VGzZk3nHhQAACg3XB52br31Vu3YsUNbt27VsGHDFB0drb17917TfY4fP16ZmZn2x7Fjx67p/gAAgOt4uroAb29v3XzzzZKkVq1aadu2bZo5c6YeeOABZWdnKyMjw+HqTlpamkJDQyVJoaGh+vbbbx22lz9bK79PYXx8fOTj4+PkIwEAAOWRy6/sXCovL09ZWVlq1aqVvLy8lJiYaF924MABHT16VOHh4ZKk8PBw7dq1S+np6fY+a9asUUBAgMLCwsq8dgAAUP649MrO+PHj1aNHD9WqVUunT5/W4sWLtWHDBn355ZcKDAzU4MGDNWbMGAUHBysgIEAjRoxQeHi42rdvL0nq1q2bwsLCNHDgQE2bNk2pqal67rnnFBsby5UbAAAgycVhJz09XY888oh+/fVXBQYGqlmzZvryyy/VtWtXSdKMGTPk7u6ufv36KSsrS5GRkZo3b559fQ8PD61YsULDhg1TeHi4/Pz8FB0drbi4OFcdEgAAKGfK3X12XIH77ACuw312AJTUdXefHQAAgGuBsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARitR2KlXr55+++23Au0ZGRmqV69eqYsCAABwlhKFncOHDys3N7dAe1ZWlo4fP17qogAAAJzF82o6f/rpp/Z/f/nllwoMDLQ/z83NVWJiourUqeO04gAAAErrqsJO7969JUlubm6Kjo52WObl5aU6dero9ddfd1pxAAAApXVVYScvL0+SVLduXW3btk1Vq1a9JkUBAAA4y1WFnXyHDh1ydh0AAADXRInCjiQlJiYqMTFR6enp9is++f7zn/+UujAAAABnKFHYmTx5suLi4tS6dWvdcMMNcnNzc3ZdAAAATlGisDN//nwlJCRo4MCBzq4HAADAqUp0n53s7Gzdfvvtzq4FAADA6UoUdh599FEtXrzY2bUAAAA4XYk+xjp//rzeeustrV27Vs2aNZOXl5fD8unTpzulOAAAgNIqUdj5/vvv1aJFC0nS7t27HZYxWBkAAJQnJQo769evd3YdAAAA10SJxuwAAABcL0p0ZadTp06X/bhq3bp1JS4IAADAmUoUdvLH6+S7cOGCduzYod27dxf4glAAAABXKlHYmTFjRqHtkyZN0pkzZ0pVEAAAgDM5dczOww8/zPdiAQCAcsWpYScpKUm+vr7O3CQAAECplOhjrL59+zo8tyxLv/76q7777js9//zzTikMAADAGUoUdgIDAx2eu7u769Zbb1VcXJy6devmlMIAAACcoURhZ8GCBc6uAwAA4JooUdjJl5ycrH379kmSGjdurJYtWzqlKAAAAGcpUdhJT0/XgAEDtGHDBgUFBUmSMjIy1KlTJ33wwQeqVq2aM2sEAAAosRLNxhoxYoROnz6tPXv26NSpUzp16pR2794tm82mJ5980tk1AgAAlFiJruysWrVKa9euVaNGjextYWFhmjt3LgOUAQBAuVKiKzt5eXny8vIq0O7l5aW8vLxSFwUAAOAsJQo7nTt31siRI5WSkmJvO378uEaPHq0uXbo4rTgAAIDSKlHYmTNnjmw2m+rUqaP69eurfv36qlu3rmw2m2bPnu3sGgEAAEqsRGN2atasqe3bt2vt2rXav3+/JKlRo0aKiIhwanEAAACldVVXdtatW6ewsDDZbDa5ubmpa9euGjFihEaMGKE2bdqocePG+uqrr65VrQAAAFftqsJOfHy8hgwZooCAgALLAgMD9dhjj2n69OlOKw4AAKC0rirs7Ny5U927dy9yebdu3ZScnFzqogAAAJzlqsJOWlpaoVPO83l6eurEiROlLgoAAMBZrirs3Hjjjdq9e3eRy7///nvdcMMNxd7e1KlT1aZNG1WqVEnVq1dX7969deDAAYc+58+fV2xsrKpUqSJ/f3/169dPaWlpDn2OHj2qqKgoVaxYUdWrV9fYsWOVk5NzNYcGAAAMdVVhp2fPnnr++ed1/vz5Asv++OMPTZw4Ub169Sr29jZu3KjY2Fh98803WrNmjS5cuKBu3brp7Nmz9j6jR4/WZ599pqVLl2rjxo1KSUlR37597ctzc3MVFRWl7OxsbdmyRQsXLlRCQoImTJhwNYcGAAAM5WZZllXczmlpabrtttvk4eGh4cOH69Zbb5Uk7d+/X3PnzlVubq62b9+ukJCQEhVz4sQJVa9eXRs3btRdd92lzMxMVatWTYsXL1b//v3t+2rUqJGSkpLUvn17rVy5Ur169VJKSop9v/Pnz9e4ceN04sQJeXt7X3G/NptNgYGByszMLHTwdWnUeeZzp24PMM3hl6NcXQKA61Rxf39f1ZWdkJAQbdmyRU2aNNH48ePVp08f9enTR88++6yaNGmir7/+usRBR5IyMzMlScHBwZKk5ORkXbhwweH+PQ0bNlStWrWUlJQkSUpKSlLTpk0d9hsZGSmbzaY9e/aUuBYAAGCGq76pYO3atfXFF1/o999/18GDB2VZlho0aKDKlSuXqpC8vDyNGjVKHTp0UJMmTSRJqamp8vb2VlBQkEPfkJAQpaam2vtcGrDyn+f3uVRWVpaysrLsz202W6lqBwAA5VeJ7qAsSZUrV1abNm2cVkhsbKx2796tr7/+2mnbLMrUqVM1efLka74fAADgeiX6bixnGz58uFasWKH169frpptusreHhoYqOztbGRkZDv3T0tIUGhpq73Pp7Kz85/l9LjV+/HhlZmbaH8eOHXPi0QAAgPLEpWHHsiwNHz5cH3/8sdatW6e6des6LG/VqpW8vLyUmJhobztw4ICOHj2q8PBwSVJ4eLh27dql9PR0e581a9YoICBAYWFhhe7Xx8dHAQEBDg8AAGCmEn+M5QyxsbFavHixPvnkE1WqVMk+xiYwMFAVKlRQYGCgBg8erDFjxig4OFgBAQEaMWKEwsPD1b59e0l/3rU5LCxMAwcO1LRp05SamqrnnntOsbGx8vHxceXhAQCAcsClYeeNN96QJN19990O7QsWLFBMTIwkacaMGXJ3d1e/fv2UlZWlyMhIzZs3z97Xw8NDK1as0LBhwxQeHi4/Pz9FR0crLi6urA4DAACUY1d1nx1TcZ8dwHW4zw6Akrom99kBAAC43hB2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjObpyp1v2rRJr776qpKTk/Xrr7/q448/Vu/eve3LLcvSxIkT9fbbbysjI0MdOnTQG2+8oQYNGtj7nDp1SiNGjNBnn30md3d39evXTzNnzpS/v78LjgjAX1WdZz53dQlAuXX45SiX7t+lV3bOnj2r5s2ba+7cuYUunzZtmmbNmqX58+dr69at8vPzU2RkpM6fP2/v89BDD2nPnj1as2aNVqxYoU2bNmno0KFldQgAAKCcc+mVnR49eqhHjx6FLrMsS/Hx8Xruued03333SZLeeecdhYSEaPny5RowYID27dunVatWadu2bWrdurUkafbs2erZs6dee+011ahRo8yOBQAAlE/ldszOoUOHlJqaqoiICHtbYGCg2rVrp6SkJElSUlKSgoKC7EFHkiIiIuTu7q6tW7cWue2srCzZbDaHBwAAMFO5DTupqamSpJCQEIf2kJAQ+7LU1FRVr17dYbmnp6eCg4PtfQozdepUBQYG2h81a9Z0cvUAAKC8KLdh51oaP368MjMz7Y9jx465uiQAAHCNlNuwExoaKklKS0tzaE9LS7MvCw0NVXp6usPynJwcnTp1yt6nMD4+PgoICHB4AAAAM5XbsFO3bl2FhoYqMTHR3maz2bR161aFh4dLksLDw5WRkaHk5GR7n3Xr1ikvL0/t2rUr85oBAED549LZWGfOnNHBgwftzw8dOqQdO3YoODhYtWrV0qhRo/Tiiy+qQYMGqlu3rp5//nnVqFHDfi+eRo0aqXv37hoyZIjmz5+vCxcuaPjw4RowYAAzsQAAgCQXh53vvvtOnTp1sj8fM2aMJCk6OloJCQl6+umndfbsWQ0dOlQZGRm64447tGrVKvn6+trXee+99zR8+HB16dLFflPBWbNmlfmxAACA8snNsizL1UW4ms1mU2BgoDIzM50+foe7qgKX5+o7qzoL73WgaNfqfV7c39/ldswOAACAMxB2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGM2YsDN37lzVqVNHvr6+ateunb799ltXlwQAAMoBI8LOkiVLNGbMGE2cOFHbt29X8+bNFRkZqfT0dFeXBgAAXMyIsDN9+nQNGTJEgwYNUlhYmObPn6+KFSvqP//5j6tLAwAALnbdh53s7GwlJycrIiLC3ubu7q6IiAglJSW5sDIAAFAeeLq6gNI6efKkcnNzFRIS4tAeEhKi/fv3F7pOVlaWsrKy7M8zMzMlSTabzen15WWdc/o2AZNci/edK/BeB4p2rd7n+du1LOuy/a77sFMSU6dO1eTJkwu016xZ0wXVAH9tgfGurgDAtXat3+enT59WYGBgkcuv+7BTtWpVeXh4KC0tzaE9LS1NoaGhha4zfvx4jRkzxv48Ly9Pp06dUpUqVeTm5nZN64Xr2Gw21axZU8eOHVNAQICrywFwjfBe/+uwLEunT59WjRo1Ltvvug873t7eatWqlRITE9W7d29Jf4aXxMREDR8+vNB1fHx85OPj49AWFBR0jStFeREQEMB/gMBfAO/1v4bLXdHJd92HHUkaM2aMoqOj1bp1a7Vt21bx8fE6e/asBg0a5OrSAACAixkRdh544AGdOHFCEyZMUGpqqlq0aKFVq1YVGLQMAAD+eowIO5I0fPjwIj+2AqQ/P76cOHFigY8wAZiF9zou5WZdab4WAADAdey6v6kgAADA5RB2AACA0Qg7AADAaIQdAABgNMIO/jLmzp2rOnXqyNfXV+3atdO3337r6pIAONGmTZt0zz33qEaNGnJzc9Py5ctdXRLKCcIO/hKWLFmiMWPGaOLEidq+fbuaN2+uyMhIpaenu7o0AE5y9uxZNW/eXHPnznV1KShnmHqOv4R27dqpTZs2mjNnjqQ/v1KkZs2aGjFihJ555hkXVwfA2dzc3PTxxx/bv0YIf21c2YHxsrOzlZycrIiICHubu7u7IiIilJSU5MLKAABlgbAD4508eVK5ubkFvj4kJCREqampLqoKAFBWCDsAAMBohB0Yr2rVqvLw8FBaWppDe1pamkJDQ11UFQCgrBB2YDxvb2+1atVKiYmJ9ra8vDwlJiYqPDzchZUBAMqCMd96DlzOmDFjFB0drdatW6tt27aKj4/X2bNnNWjQIFeXBsBJzpw5o4MHD9qfHzp0SDt27FBwcLBq1arlwsrgakw9x1/GnDlz9Oqrryo1NVUtWrTQrFmz1K5dO1eXBcBJNmzYoE6dOhVoj46OVkJCQtkXhHKDsAMAAIzGmB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwCMlJCQoKCgoFJvx83NTcuXLy/1dgC4DmEHQLkVExOj3r17u7oMANc5wg4AADAaYQfAdWn69Olq2rSp/Pz8VLNmTT3xxBM6c+ZMgX7Lly9XgwYN5Ovrq8jISB07dsxh+SeffKLbbrtNvr6+qlevniZPnqycnJyyOgwAZYCwA+C65O7urlmzZmnPnj1auHCh1q1bp6efftqhz7lz5zRlyhS988472rx5szIyMjRgwAD78q+++kqPPPKIRo4cqb179+rNN99UQkKCpkyZUtaHA+Aa4otAAZRbMTExysjIKNYA4WXLlunxxx/XyZMnJf05QHnQoEH65ptv7N9uv3//fjVq1Ehbt25V27ZtFRERoS5dumj8+PH27SxatEhPP/20UlJSJP05QPnjjz9m7BBwHfN0dQEAUBJr167V1KlTtX//ftlsNuXk5Oj8+fM6d+6cKlasKEny9PRUmzZt7Os0bNhQQUFB2rdvn9q2baudO3dq8+bNDldycnNzC2wHwPWNsAPgunP48GH16tVLw4YN05QpUxQcHKyvv/5agwcPVnZ2drFDypkzZzR58mT17du3wDJfX19nlw3ARQg7AK47ycnJysvL0+uvvy539z+HHn744YcF+uXk5Oi7775T27ZtJUkHDhxQRkaGGjVqJEm67bbbdODAAd18881lVzyAMkfYAVCuZWZmaseOHQ5tVatW1YULFzR79mzdc8892rx5s+bPn19gXS8vL40YMUKzZs2Sp6enhg8frvbt29vDz4QJE9SrVy/VqlVL/fv3l7u7u3bu3Kndu3frxRdfLIvDA1AGmI0FoFzbsGGDWrZs6fB49913NX36dL3yyitq0qSJ3nvvPU2dOrXAuhUrVtS4ceP097//XR06dJC/v7+WLFliXx4ZGakVK1Zo9erVatOmjdq3b68ZM2aodu3aZXmIAK4xZmMBAACjcWUHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKP9P5szx5cki5pwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_type = []\n",
    "\n",
    "for waveform, label in test_loader:\n",
    "    label_type.append(label)\n",
    "\n",
    "# plot label type distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten the list of labels and convert to numpy array\n",
    "labels_flat = np.concatenate(label_type)\n",
    "\n",
    "# Count the number of each label\n",
    "(unique, counts) = np.unique(labels_flat, return_counts=True)\n",
    "\n",
    "# Plot the distribution\n",
    "plt.bar(unique, counts)\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Labels in Training Data')\n",
    "plt.xticks(unique)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canary-vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
